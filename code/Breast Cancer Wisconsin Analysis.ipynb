{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and data loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Supress the warnings from final output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "column_names = ['ID number', 'Diagnosis', \n",
    "               'Mean radius','Mean texture','Mean perimeter','Mean area','Mean smoothness','Mean compactness','Mean concavity','Mean concave points','Mean symmetry','Mean fractal dimension',\n",
    "               'Standard error radius','Standard error texture','Standard error perimeter','Standard error area','Standard error smoothness','Standard error compactness','Standard error concavity','Standard error concave points','Standard error symmetry','Standard error fractal dimension',\n",
    "               'Largest radius','Largest texture','Largest perimeter','Largest area','Largest smoothness','Largest compactness','Largest concavity','Largest concave points','Largest symmetry','Largest fractal dimension']\n",
    "\n",
    "wdbc_data = pd.read_csv('../input/wdbc.data', header=None, names=column_names)\n",
    "target_data = wdbc_data['Diagnosis']\n",
    "feature_data = wdbc_data.iloc[:,2:]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoded_target_data = encoder.fit_transform(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (398, 30)\n",
      "x_test.shape: (171, 30)\n",
      "y_train.shape: (398,)\n",
      "y_test.shape: (171,)\n",
      "standardised_x_train.shape: (398, 30)\n",
      "standardised_x_test.shape: (171, 30)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature_data, encoded_target_data, train_size=0.7, test_size=0.3, random_state=4)\n",
    "\n",
    "# Directly confirm their sizes \n",
    "print(\"x_train.shape: {}\".format(x_train.shape))\n",
    "print(\"x_test.shape: {}\".format(x_test.shape))\n",
    "print(\"y_train.shape: {}\".format(y_train.shape))\n",
    "print(\"y_test.shape: {}\".format(y_test.shape))\n",
    "\n",
    "# Standardisation\n",
    "scaler = StandardScaler().fit(x_train)\n",
    "standardised_x_train = scaler.transform(x_train)\n",
    "standardised_x_test = scaler.transform(x_test)\n",
    "\n",
    "# Directly confirm their sizes\n",
    "print(\"standardised_x_train.shape: {}\".format(standardised_x_train.shape))\n",
    "print(\"standardised_x_test.shape: {}\".format(standardised_x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Accuracy Score: 0.9532163742690059\n",
      "OOB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       117\n",
      "           1       0.88      0.98      0.93        54\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       171\n",
      "   macro avg       0.94      0.96      0.95       171\n",
      "weighted avg       0.96      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets start with sklearn's LinearSVC\n",
    "# Create estimator and get predictions\n",
    "lin_svc = LinearSVC(random_state=4)\n",
    "lin_svc.fit(standardised_x_train, y_train)\n",
    "lin_svc_preds = lin_svc.predict(standardised_x_test)\n",
    "# Test predictions and print output\n",
    "print('OOB Accuracy Score: {}'.format(accuracy_score(y_test, lin_svc_preds)))\n",
    "print('OOB Classification Report:')\n",
    "print(classification_report(y_test, lin_svc_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, for out of box usage that is really good. A solid 95.3% accuracy. Interestingly, while the recall is similar for both, and the precision for benign (0) is very high, the precision for malignant (1) is only 0.88. Normally, I would think this a bad thing, but since the objective here is to find out who needs cancer treatment I think that - combined with a recall of 0.98, that's fine. If they are found to likely have malignant tumours, is is better that this test flags up harmless cases for further analysis rather than fails to flag up actual malignant tumours - one results in unnecessary further medical examinations, the other kills people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Accuracy Score: 0.9649122807017544\n",
      "OOB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       117\n",
      "           1       0.93      0.96      0.95        54\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       171\n",
      "   macro avg       0.96      0.96      0.96       171\n",
      "weighted avg       0.97      0.96      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Next, lets try a KNeighborsClassifier\n",
    "# Create estimator and get predictions\n",
    "knc = KNeighborsClassifier()\n",
    "knc.fit(standardised_x_train, y_train)\n",
    "knc_pred = knc.predict(standardised_x_test)\n",
    "# Test predictions and print output\n",
    "print('OOB Accuracy Score: {}'.format(accuracy_score(y_test, knc_pred)))\n",
    "print('OOB Classification Report:')\n",
    "print(classification_report(y_test, knc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An even better accuracy score! 96.5% is very good. Additionally, while the precision score for benign (0) is 0.01 worse, it's recall is 0.03 higher. Unfortunately the recall of malignant (1) fell by 0.02, though it's precision rose by 0.05. Overall the f1-scores were both higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Accuracy Score: 0.9766081871345029\n",
      "OOB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       117\n",
      "           1       0.93      1.00      0.96        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       171\n",
      "   macro avg       0.97      0.98      0.97       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Next, lets try SVC\n",
    "# Create estimator and get predictions\n",
    "svc = SVC(random_state=4)\n",
    "svc.fit(standardised_x_train, y_train)\n",
    "svc_pred = svc.predict(standardised_x_test)\n",
    "# Test predictions and print output\n",
    "print('OOB Accuracy Score: {}'.format(accuracy_score(y_test, svc_pred)))\n",
    "print('OOB Classification Report:')\n",
    "print(classification_report(y_test, svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet another increase in accuracy - this time to 97.7%! Even better, the recall of the malignant (1) case is 1.00, which means that not a single actually malignant tumour in the test set was missed! On the other hand, 7% of diagnoses of malignant were incorrect, which means a lot of unnecessary, uncomfortable medical tests. But hey, at least it's 7% uncomfortable and not 7% dead because they got their cancer misclassified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV best estimator: SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=0, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=4,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "GridSearchCV best estimator accuracy score: 0.9824561403508771\n",
      "GridSearchCV best estimator classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99       117\n",
      "           1       0.95      1.00      0.97        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       171\n",
      "   macro avg       0.97      0.99      0.98       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carrying on with SVC, I'll try a GridSearchCV to see if the first >97.5% classifier can get any better. \n",
    "# Create param dict\n",
    "parameters = {'kernel': ['rbf','poly','sigmoid'],\n",
    "              'degree': np.arange(0,5).tolist(),\n",
    "              'C': np.logspace(-3,2,6).tolist()}\n",
    "\n",
    "# Create and run gridsearch\n",
    "svc_grid = GridSearchCV(estimator=SVC(random_state=4), param_grid=parameters, refit=True, cv=5, scoring='accuracy')\n",
    "svc_grid.fit(standardised_x_train, y_train)\n",
    "\n",
    "# Get best score, estimator, and classification report\n",
    "print('GridSearchCV best estimator: {}\\n'.format(svc_grid.best_estimator_))\n",
    "print('GridSearchCV best estimator accuracy score: {}'.format(accuracy_score(y_test, svc_grid.best_estimator_.predict(standardised_x_test))))\n",
    "print('GridSearchCV best estimator classification Report:')\n",
    "print(classification_report(y_test, svc_grid.best_estimator_.predict(standardised_x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out you can get better! What does it take? More regularisation! 10 times more, to be exact.  \n",
    "With an accuracy score of 98.2%, and with an incrase of both classes f1-scores, this is looking to be a very useful classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "A dataset made of pre-engineered continuous ratio medical data, with no individually linearly separable features, is classifiable to a very high level of accuracy: 98.25%.  \n",
    "With this level of accuracy - and in particular with this level of recall on the malignant (1) class, I don't see the need to engage in any further optimisation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
